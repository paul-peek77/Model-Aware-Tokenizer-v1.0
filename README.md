## Modelâ€‘Aware Tokenizer (The Tokenator)

### A multiâ€‘format text extractor, modelâ€‘aware tokenizer, and chunkâ€‘analysis engine.

---

This project is provided for portfolio review only. No permission is granted for reuse, modification, or redistribution.

---

Overview

Tokenator is a fullâ€‘stack tool for analyzing token counts across multiple LLM models. It accepts a wide range of file formats, extracts text using bestâ€‘effort converters, and evaluates token usage using:

- tiktoken (preferred, exact)
- gptâ€‘3â€‘encoder (fallback for older GPTâ€‘2/Davinci models)
- heuristic estimation (when no encoder is available)

It includes:

- a browser UI
- a Node.js backend
- a workerâ€‘thread engine for large files
- an Electron wrapper for desktop use
- a local runner with automatic browser lifecycle
- a test harness for validation

This project demonstrates systems thinking, multiâ€‘format parsing, concurrency, and modelâ€‘aware tokenization logic.

---

Features

ğŸ§© Multiâ€‘Format Extraction

Tokenator extracts text from:

- TXT / MD
- HTML / XHTML
- PDF
- DOCX
- PPTX
- EPUB / ZIP archives
- CSV / JSON
- Images (PNG/JPG/WebP) via optional OCR
- Binary files (base64 fallback)

Extraction is bestâ€‘effort and capped for safety.

ğŸ§  Modelâ€‘Aware Tokenization

Supports:

- GPTâ€‘4 / GPTâ€‘4o
- GPTâ€‘3.5 variants
- Davinci / GPTâ€‘2 encodings
- Gemini models
- Gemma models
- Custom model specs (model:encoding:context or model|encoding|context)

Tokenization uses:

1. Exact tiktoken encoding when available
2. Exact GPTâ€‘3â€‘encoder for older models
3. Heuristic fallback using charsâ€‘perâ€‘token ratios

ğŸ“¦ Chunking & Context Analysis

For each model:

- token count
- context window
- chunks needed
- optional perâ€‘chunk previews

âš¡ Workerâ€‘Thread Acceleration

Large files (>2MB) automatically route through a worker thread:

- file written to disk
- worker processes text
- results returned asynchronously
- file cleaned up

ğŸ–¥ï¸ Electron Desktop App

A lightweight GUI wrapper:

- starts the server
- opens a dedicated browser window
- shuts down the server when the window closes

ğŸ§ª Test Harness

A simple test script validates:

- upload endpoint
- JSON structure
- snippet token count
- model count entries

---

Architecture

    [Upload]
        â†“
    [Extraction Pipeline]
        â†“
    [Tokenizer Layer]
        â†“
    [Chunker]
        â†“
    [Response JSON]

Extraction Pipeline

- Detects file type
- Routes to appropriate extractor
- Applies OCR if enabled
- Caps extracted text to 5MB

Tokenizer Layer

- Parses model specs
- Selects encoder
- Computes token counts
- Computes chunks needed

Worker Path

Used for large files:

    [Disk Write] â†’ [Worker Thread] â†’ [Token Counts] â†’ [Cleanup]

---

Repository Structure

    tokenator/
        server.js
        tokenWorker.js
        electron-main.js
        run_local.sh
        public/
            index.html
            script.js
        test/
            run_tests.sh
        uploads/            (ignored)
        server.out          (ignored)
        server.pid          (ignored)
        package.json
        INSTALL.md
        README.md

---

Usage

Install
`
npm install
`

Optional:
`
npm install tiktoken
npm install gpt-3-encoder
npm install tesseract.js
`

Run the server
`
npm start
`
Open:  
http://localhost:3000

Run with Electron
`
npm run run:gui
`

Run locally with autoâ€‘shutdown
`
npm run run:local
`

---

API

POST /upload
Multipart formâ€‘data:

- file â€” uploaded file
- models â€” commaâ€‘separated model specs
- enableOcr=true
- expandArchives=true
- chunkSize=2000
- useWorker=true

Returns JSON:

- filename
- size
- ext
- derivedFrom
- snippet
- snippetTokens
- tokenCounts (per model)

---

Security Notes

- No authentication â€” do not deploy publicly
- Upload limit: 50MB
- Extracted text capped at 5MB
- Files processed in memory or temporary disk
- No persistent storage

---

Why This Project Matters

The Tokenator demonstrates:

- fullâ€‘stack engineering
- multiâ€‘format parsing
- concurrency and worker threads
- modelâ€‘aware logic
- Electron desktop integration
- robust error handling
- developerâ€‘friendly UX
- testability and reproducibility

Itâ€™s a practical tool with real engineering depth â€” the kind of project that shows you can design, build, and ship systems that solve real problems.
